{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e000765",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "So far... we have over 700 scripts devolved into bag-of-words, along with ratings (from 1 to 10). Let's start modeling!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1429edfd",
   "metadata": {},
   "source": [
    "We'll start by loading the data from the csv file, deleting the unnecessary columns, dividing into X (features) and y (ratings), and creating a training set and a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6d8cf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ratingsScripts = pd.read_csv('ratingsAndScriptsBagOfWords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43d751ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsScriptsML = ratingsScripts.drop(['movie_name','tconst','titleType','primaryTitle','startYear','genres','movie_title','numVotes'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "290c92ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ratingsScriptsML.drop('averageRating', axis= 1)\n",
    "y = round(ratingsScriptsML['averageRating'],0)\n",
    "# round the ratings so we can fit a random forest\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X,y,test_size = .2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b69168",
   "metadata": {},
   "source": [
    "Confirm there are no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "635e1a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>...</th>\n",
       "      <th>yourselves</th>\n",
       "      <th>youth</th>\n",
       "      <th>zero</th>\n",
       "      <th>zip</th>\n",
       "      <th>zips</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zooms</th>\n",
       "      <th>averageRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 6690 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0.1, Unnamed: 0, 00, 000, 10, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 11, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 12, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 13, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 14, 140, 141, 142, 143, 144, 145, 146, 147, 148, 15, 150, 151, 16, 160, 17, 18, 180, 19, 1st, 20, 200, 21, 22, 23, 24, 25, 250, 26, 27, 28, 29, 2nd, 30, 300, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 6690 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicateRowsDF = ratingsScriptsML[ratingsScriptsML.duplicated()]\n",
    "duplicateRowsDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4016727",
   "metadata": {},
   "source": [
    "We have too many features. Let's reduce that with SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86da3c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components = 27, random_state = 42)\n",
    "svd.fit(X_tr) # make sure only fit to the training set\n",
    "X_tr_transformed = svd.transform(X_tr)\n",
    "X_te_transformed = svd.transform(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c89f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c500b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_curve,roc_auc_score\n",
    "from sklearn.metrics import accuracy_score,log_loss\n",
    "from matplotlib import pyplot\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da20389d",
   "metadata": {},
   "source": [
    "Create a validation set to leave the testing to last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b871bbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_tr_transformed,y_tr,test_size = .2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310b3d17",
   "metadata": {},
   "source": [
    "First let's try a very simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec598670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_val_mean = [round(np.mean(y_train),0)] * len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "176d4d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.0, 6.0, 6.0, 6.0, 6.0]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_mean[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28cc2661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Average: Accuracy=0.241\n",
      "Simple Average: f1-score=0.094\n"
     ]
    }
   ],
   "source": [
    "ac = accuracy_score(y_val, y_val_mean)\n",
    "\n",
    "f1 = f1_score(y_val, y_val_mean, average='weighted')\n",
    "\n",
    "print('Simple Average: Accuracy=%.3f' % (ac))\n",
    "\n",
    "print('Simple Average: f1-score=%.3f' % (f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208ca05f",
   "metadata": {},
   "source": [
    "So we have lots of room for improvement!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810ab3c9",
   "metadata": {},
   "source": [
    "Try a random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f1d5ec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfc_and_print_scores(X_tra, y_tra, X_va, y_va, n_estimators, max_depth,criterion):\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth = max_depth,criterion=criterion, random_state = 1,n_jobs=-1)\n",
    "    model_res = clf.fit(X_tra, y_tra)\n",
    "    y_pred = model_res.predict(X_va)\n",
    "\n",
    "    ac = accuracy_score(y_va, y_pred)\n",
    "\n",
    "    f1 = f1_score(y_va, y_pred, average='weighted')\n",
    "\n",
    "    print('Random Forest: Accuracy=%.3f' % (ac))\n",
    "\n",
    "    print('Random Forest: f1-score=%.3f' % (f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a660563d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Accuracy=0.345\n",
      "Random Forest: f1-score=0.309\n"
     ]
    }
   ],
   "source": [
    "rfc_and_print_scores(X_train, y_train, X_val, y_val,300,None,'gini')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed392048",
   "metadata": {},
   "source": [
    "Well that's better - especially the F1 score!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0b503c",
   "metadata": {},
   "source": [
    "Let's see what happens when we change the number of estimators - we don't have a lot of scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4f33fe7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Accuracy=0.362\n",
      "Random Forest: f1-score=0.324\n"
     ]
    }
   ],
   "source": [
    "rfc_and_print_scores(X_train, y_train, X_val, y_val,150,None,'gini')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674208a9",
   "metadata": {},
   "source": [
    "That's a little better. What happens when we drop the estimators more?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "04da107e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Accuracy=0.345\n",
      "Random Forest: f1-score=0.314\n"
     ]
    }
   ],
   "source": [
    "rfc_and_print_scores(X_train, y_train, X_val, y_val,100,None,'gini')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0615ac",
   "metadata": {},
   "source": [
    "Accuracy goes down again. So 150 looks like a good number of estimators for a random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc9b317",
   "metadata": {},
   "source": [
    "What about linear regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "662acb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: Accuracy=0.250\n",
      "Linear Regression: f1-score=0.147\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "y_pred_lr = lr.predict(X_val)\n",
    "\n",
    "ac = accuracy_score(y_val, np.round(y_pred_lr,0))\n",
    "\n",
    "f1 = f1_score(y_val, np.round(y_pred_lr,0), average='weighted')\n",
    "\n",
    "print('Linear Regression: Accuracy=%.3f' % (ac))\n",
    "\n",
    "print('Linear Regression: f1-score=%.3f' % (f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82b9b9f",
   "metadata": {},
   "source": [
    "Not as good as the random forest - barely better than the simple model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9396a25",
   "metadata": {},
   "source": [
    "We can try gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f03c0c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3aaf25ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score : 0.328\n",
      "F1 score: 0.245\n",
      "\n",
      "Learning rate:  0.1\n",
      "Accuracy score : 0.345\n",
      "F1 score: 0.278\n",
      "\n",
      "Learning rate:  0.25\n",
      "Accuracy score : 0.336\n",
      "F1 score: 0.281\n",
      "\n",
      "Learning rate:  0.5\n",
      "Accuracy score : 0.293\n",
      "F1 score: 0.278\n",
      "\n",
      "Learning rate:  0.75\n",
      "Accuracy score : 0.310\n",
      "F1 score: 0.287\n",
      "\n",
      "Learning rate:  1\n",
      "Accuracy score : 0.302\n",
      "F1 score: 0.299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "for learning_rate in learning_rates:\n",
    "    gb = GradientBoostingClassifier(n_estimators=20, learning_rate = learning_rate, max_features=2, max_depth = 2, random_state = 0)\n",
    "    gb.fit(X_train, y_train)\n",
    "    y_pred_gb = gb.predict(X_val)\n",
    "    ac = accuracy_score(y_val, np.round(y_pred_gb,0))\n",
    "    f1 = f1_score(y_val, np.round(y_pred_gb,0), average='weighted')\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score : {0:.3f}\".format(ac))\n",
    "    print(\"F1 score: {0:.3f}\".format(f1))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faee3a1",
   "metadata": {},
   "source": [
    "The random forest performed better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277b47a7",
   "metadata": {},
   "source": [
    "Let's make sure we have the best random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0409e744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trees:  130\n",
      "Random Forest: Accuracy=0.371\n",
      "Random Forest: f1-score=0.332\n",
      "Number of trees:  140\n",
      "Random Forest: Accuracy=0.362\n",
      "Random Forest: f1-score=0.322\n",
      "Number of trees:  150\n",
      "Random Forest: Accuracy=0.362\n",
      "Random Forest: f1-score=0.324\n",
      "Number of trees:  160\n",
      "Random Forest: Accuracy=0.371\n",
      "Random Forest: f1-score=0.330\n",
      "Number of trees:  170\n",
      "Random Forest: Accuracy=0.345\n",
      "Random Forest: f1-score=0.309\n"
     ]
    }
   ],
   "source": [
    "num_trees_list = [130, 140, 150, 160, 170]\n",
    "for tree in num_trees_list:\n",
    "    print('Number of trees: ', tree)\n",
    "    rfc_and_print_scores(X_train, y_train, X_val, y_val,tree,None,'gini')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbbd5d7",
   "metadata": {},
   "source": [
    "It looks like 130 trees gives us a best score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70c6bdf",
   "metadata": {},
   "source": [
    "Let's tune another hyper-parameter, max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5ccdb9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max depth:  2\n",
      "Random Forest: Accuracy=0.319\n",
      "Random Forest: f1-score=0.236\n",
      "Max depth:  5\n",
      "Random Forest: Accuracy=0.379\n",
      "Random Forest: f1-score=0.292\n",
      "Max depth:  10\n",
      "Random Forest: Accuracy=0.362\n",
      "Random Forest: f1-score=0.320\n",
      "Max depth:  15\n",
      "Random Forest: Accuracy=0.379\n",
      "Random Forest: f1-score=0.338\n",
      "Max depth:  None\n",
      "Random Forest: Accuracy=0.371\n",
      "Random Forest: f1-score=0.332\n"
     ]
    }
   ],
   "source": [
    "max_depths = [2, 5, 10, 15, None]\n",
    "for depth in max_depths:\n",
    "    print('Max depth: ', depth)\n",
    "    rfc_and_print_scores(X_train, y_train, X_val, y_val,130,depth,'gini')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1119f2aa",
   "metadata": {},
   "source": [
    "Looks like limiting the depth of the trees to 15 gives us slightly better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194dc98d",
   "metadata": {},
   "source": [
    "Let's check the criterion, given our other hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a3441b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criterion:  gini\n",
      "Random Forest: Accuracy=0.379\n",
      "Random Forest: f1-score=0.338\n",
      "Criterion:  entropy\n",
      "Random Forest: Accuracy=0.328\n",
      "Random Forest: f1-score=0.304\n",
      "Criterion:  log_loss\n",
      "Random Forest: Accuracy=0.328\n",
      "Random Forest: f1-score=0.304\n"
     ]
    }
   ],
   "source": [
    "crits = ['gini', 'entropy', 'log_loss']\n",
    "for crit in crits:\n",
    "    print('Criterion: ', crit)\n",
    "    rfc_and_print_scores(X_train, y_train, X_val, y_val,130,15,crit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a4e4d4",
   "metadata": {},
   "source": [
    "The default 'gini' score is the best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe45c39",
   "metadata": {},
   "source": [
    "So it looks like our best model is a random forest with 130 trees, max depth of 15, and the default 'gini' criterion for splitting nodes. Let's test it on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2cf3a501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Accuracy=0.345\n",
      "Random Forest: f1-score=0.305\n"
     ]
    }
   ],
   "source": [
    "rfc_and_print_scores(X_train, y_train, X_te_transformed, y_te,130,15,'gini')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c6e54d",
   "metadata": {},
   "source": [
    "So we have a 34.5% chance of finding a good script for our new movie!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad5a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
